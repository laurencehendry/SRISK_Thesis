library(base)
library(rio) # swiss army knife for imports
library(plyr) # count occurences
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # nice plots
library(stargazer) # nicer regression output which looks like a real publication
library(car) # scatterplots 
library(httr) # scraping from http sites
library(XML) # Tool for  generating XML file
library(WDI) # Scraping Data from the World Bank 
library(countrycode) # provides world bank country codes 
library(DataCombine) #merge package
library(lubridate) #provides functions to extract date-time components
library(rdd) #sharp and fuzzy regression discontinuity design tool


############################
## THE GRAND MERGE
############################

setwd("/Users/laurencehendry/GoogleDrive/Master Thesis - Shared/Quantitative Sources/V-Lab Datasets/European_Firms_2")
    
all_files <- list.files()

# Create a NULL object to combine the individual files into
combined <- NULL

for (i in all_files) {
  # Load and combine only if the file is a csv
  if (tools::file_ext(i) == 'csv') {
    # Read file
    temp <- import(i)
    
    # Create file ID from the file name and move to the front
    file_id <- gsub(pattern = '.csv', replacement = '', i)
    message(file_id)
    temp$file_id <- file_id
    temp <- MoveFront(temp, 'file_id')
    
    # Bind to the main data frame
    combined <- bind_rows(combined, temp)
    
  } else {
    message('-- Not CSV --')
  }
}

############################
## GETTING RID OF EXTRA VARIABLES
############################

rm(all_files, file_id, i, temp)

############################
## RENAME THE VARIABLES
############################

combined.safe <- combined

combined$V8 = NULL

names(combined)[names(combined) == "file_id"] <- 'Code'
names(combined)[names(combined) == "V1"] <- 'Days'
names(combined)[names(combined) == "V2"] <- 'Marginal Expected Shortfall (MES)'
names(combined)[names(combined) == "V3"] <- 'Daily Variance for the firm that day'
names(combined)[names(combined) == "V4"] <- 'Beta of the firm with respect to MSCI World Index (Rob Engle Dynamic Conditional Beta Model)'
names(combined)[names(combined) == "V5"] <- 'Correlation of the firm to MSCI World Index (uses asymmetric dynamic conditional correlation model)'
names(combined)[names(combined) == "V6"] <- 'Firm Leverage Ratio'
names(combined)[names(combined) == "V7"] <- 'SRISK'
names(combined)[names(combined) == "V9"] <- 'Firm Market Capitalisation in USD'

############################
## FORMAT THE DATE
############################

?strptime #discover date-time conversion function possibilities
#format(sys.Date(), "%a %b %d") #failed thought
#the dates were entered/formatted in excel. We can therefore seek matches once this step is complete to later determine whether
#1900-01-01 or 1904-01-01 were used (since these are the two start date conventions used by excel)
#as.Date(36690, origin = "1900-01-01") #example for one value


#dates <- as.Date("Days", origin = "1900-01-01") #attempt to convert entire date column
combined$DateProper <- as.Date(combined$Days, origin = '1900-01-01')


############################
## ADDITIONAL VARIABLES: TRADING NAME, COUNTRY, STATUS
############################

#convert the accompanying .dat file into Index.csv and import into R

setwd("/Users/laurencehendry/GoogleDrive/Master Thesis - Shared/Quantitative Sources/V-Lab Datasets/European_Firms_2/Working")

allvars <- merge(Index, combined, by="Code")


############################
## SORT DATASET CHRONOLOGICALLY
############################
#order(allvars$Date)

allvars2 <- arrange(allvars, Days)

############################
## WRITE .CSV COMMAND
############################
write.csv(allvars2, file = "combined_04122015.csv")

############################
## SHARP AND FUZZY REGRESSION DISCONTINUITY ANALYSIS
############################

??rdd
?DCdensity

#https://cran.r-project.org/web/packages/rdd/rdd.pdf

names(allvars2)[8] <- SRISK
IKbandwith(allvars2$Days, allvars2$SRISK, cutpoint = NULL, verbose = FALSE, kernel = "triangular")





